{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "curious-incidence",
   "metadata": {},
   "source": [
    "# 实例: 实现多层神经网络\n",
    "\n",
    "<img src=\"https://i.loli.net/2021/03/23/WQFjNlovuXR4gLP.png\" alt=\"image-20210323104306163\" style=\"zoom:50%;\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "occupied-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-rebel",
   "metadata": {},
   "source": [
    "1) 加载数据, 转换为numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tight-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1],TRAIN_URL)\n",
    "\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1],TEST_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hollow-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris_train = pd.read_csv(train_path,header=0)\n",
    "df_iris_test = pd.read_csv(test_path,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "established-merchant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 5), (30, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转化为NumPy数组\n",
    "iris_train = np.array(df_iris_train)\n",
    "iris_test = np.array(df_iris_test)\n",
    "\n",
    "iris_train.shape, iris_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-behalf",
   "metadata": {},
   "source": [
    "2) 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "yellow-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取属性和标签\n",
    "x_train = iris_train[:,0:4]\n",
    "y_train = iris_train[:,4]\n",
    "\n",
    "x_test = iris_test[:,0:4]\n",
    "y_test = iris_test[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adult-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中心化\n",
    "x_train=x_train-np. mean(x_train, axis=0)\n",
    "x_test=x_test-np. mean(x_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "retired-macintosh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([120, 4]),\n",
       " TensorShape([120, 3]),\n",
       " TensorShape([30, 4]),\n",
       " TensorShape([30, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转化为float32及用one-hot编码\n",
    "X_train=tf. cast(x_train, tf.float32)\n",
    "Y_train=tf. one_hot(tf. constant (y_train, dtype=tf. int32), 3)\n",
    "\n",
    "X_test=tf. cast(x_test, tf.float32)\n",
    "Y_test=tf. one_hot(tf. constant (y_test, dtype=tf. int32), 3)\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-latitude",
   "metadata": {},
   "source": [
    "3） setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "agricultural-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.5\n",
    "iter = 50\n",
    "\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-methodology",
   "metadata": {},
   "source": [
    "4) Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outer-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(612)\n",
    "W1=tf .Variable (np. random. randn(4,16), dtype = tf.float32) \n",
    "B1=tf.Variable (np. zeros([16]),dtype =tf.float32)\n",
    "W2=tf .Variable (np. random. randn(16,3), dtype = tf.float32) \n",
    "B2=tf.Variable (np. zeros([3]),dtype =tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-therapist",
   "metadata": {},
   "source": [
    "5) Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "editorial-shape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, Train Acc: 0.5666666626930237, Train Loss: 1.0732754468917847, Test Acc: 0.6333333253860474, Test Loss: 0.9036608338356018\n",
      "i: 10, Train Acc: 0.9416666626930237, Train Loss: 0.20551170408725739, Test Acc: 0.9333333373069763, Test Loss: 0.25185343623161316\n",
      "i: 20, Train Acc: 0.9416666626930237, Train Loss: 0.14929643273353577, Test Acc: 1.0, Test Loss: 0.16599898040294647\n",
      "i: 30, Train Acc: 0.9583333134651184, Train Loss: 0.12197737395763397, Test Acc: 1.0, Test Loss: 0.12392842024564743\n",
      "i: 40, Train Acc: 0.9583333134651184, Train Loss: 0.10438035428524017, Test Acc: 1.0, Test Loss: 0.09921766072511673\n",
      "i: 50, Train Acc: 0.9583333134651184, Train Loss: 0.09217057377099991, Test Acc: 1.0, Test Loss: 0.08468139916658401\n"
     ]
    }
   ],
   "source": [
    "acc_train =[]\n",
    "acc_test =[]\n",
    "cce_train= []\n",
    "cce_test =[]\n",
    "\n",
    "for i in range(iter+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        Hidden_train = tf.nn.relu(tf.matmul(X_train,W1)+B1)\n",
    "        PRED_train = tf.nn.softmax(tf.matmul(Hidden_train,W2)+B2)\n",
    "        Loss_train = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true=Y_train,y_pred=PRED_train))\n",
    "        \n",
    "        \n",
    "    Hidden_test=tf.nn.relu(tf.matmul(X_test,W1)+B1)    \n",
    "    PRED_test = tf.nn.softmax(tf.matmul(Hidden_test,W2)+B2)\n",
    "    Loss_test = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true=Y_test,y_pred=PRED_test))\n",
    "        \n",
    "    accuracy_train = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(PRED_train.numpy(),axis=1),y_train),tf.float32))\n",
    "    accuracy_test = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(PRED_test.numpy(),axis=1),y_test),tf.float32))\n",
    "    \n",
    "    acc_train.append(accuracy_train)\n",
    "    acc_test.append(accuracy_test)\n",
    "    cce_train.append(Loss_train)\n",
    "    cce_test.append(Loss_test)\n",
    "    \n",
    "    grads = tape.gradient(Loss_train,[W1,B1,W2,B2])\n",
    "    W1.assign_sub(learn_rate*grads[0])\n",
    "    B1.assign_sub(learn_rate*grads[1])\n",
    "    W2.assign_sub(learn_rate*grads[2])\n",
    "    B2.assign_sub(learn_rate*grads[3])\n",
    "    \n",
    "    if i % display_step ==0:\n",
    "        print(f'i: {i}, Train Acc: {accuracy_train}, Train Loss: {Loss_train}, Test Acc: {accuracy_test}, Test Loss: {Loss_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
